# ğŸ‘— Virtual Try-On AI Backend

This is the **backend service** for the Virtual Try-On AI project.  
It powers the frontend (built with Lovable) by providing an API to detect clothing, segment garments, and generate try-on results using **Roboflow, SAM (Segment Anything), and Segmind Inpainting**.

---

## ğŸš€ Features
- Upload a personâ€™s photo and **detect clothing items** (upper/lower body).
- **Segment clothing regions** using [Metaâ€™s SAM](https://segment-anything.com/).
- Perform **virtual try-on** using [Segmind Inpainting API](https://segmind.com/).
- Expose APIs via [FastAPI](https://fastapi.tiangolo.com/).
- Supports **GPU acceleration** if available.

---

## ğŸ“‚ Project Structure
```

backend/
â”œâ”€â”€ virtual\_tryon.py      # Core class with detection, segmentation, and try-on logic
â”œâ”€â”€ main.py               # FastAPI app exposing API endpoints
â”œâ”€â”€ requirements.txt      # Python dependencies
â”œâ”€â”€ uploads/              # Temporary uploaded images
â”œâ”€â”€ outputs/              # Generated output images
â””â”€â”€ .env                  # Environment variables (API keys)

````


## âš™ï¸ Setup Instructions

### 1ï¸âƒ£ Clone the repository
```bash
git clone https://github.com/your-username/Virtual_tryon.git
cd virtual-tryon-backend
````

### 2ï¸âƒ£ Create a virtual environment

```bash
python -m venv venv
source venv/bin/activate   # On Linux/Mac
venv\Scripts\activate      # On Windows
```

### 3ï¸âƒ£ Install dependencies

```bash
pip install -r requirements.txt
```

### 4ï¸âƒ£ Setup environment variables

Create a `.env` file in the project root:

```
ROBOFLOW_API_KEY=your_roboflow_api_key
SEGMIND_API_KEY=your_segmind_api_key
```

### 5ï¸âƒ£ Run the FastAPI server

```bash
uvicorn main:app --host 0.0.0.0 --port 8000 --reload
```

The API will be available at:
ğŸ‘‰ `http://localhost:8000`

Interactive API docs (Swagger UI):
ğŸ‘‰ `http://localhost:8000/docs`

---

## ğŸ“¡ API Endpoints

### ğŸ”¹ Health Check

```http
GET /
```

Returns a simple health status.

---

### ğŸ”¹ Detect Clothing

```http
POST /detect-clothing
```

**Request:**

* `file`: Image file

**Response:**

* Detected clothing items
* Available regions (`upper` / `lower`)

---

### ğŸ”¹ Virtual Try-On

```http
POST /virtual-tryon
```

**Request:**

* `file`: Image file
* `prompt`: Text prompt describing desired clothing (e.g., `"red leather jacket"`)
* `region`: `"upper"` or `"lower"`

**Response:**

* Original image (base64)
* Masked clothing region (base64)
* Generated try-on result (base64)

---

## ğŸ“¦ Dependencies

Main libraries and models used:

* **FastAPI** â€“ Web API framework
* **Torch** â€“ Deep learning framework
* **Ultralytics SAM** â€“ Segment Anything model
* **Roboflow Inference SDK** â€“ Clothing detection
* **Segmind API** â€“ Inpainting for virtual try-on
* **OpenCV / Pillow / NumPy** â€“ Image processing
* **Uvicorn** â€“ ASGI server

See `requirements.txt` for full details.

---

## ğŸ–¼ï¸ Example Workflow

1. Upload an image of a person.
2. API detects **clothing regions** (upper/lower).
3. User selects a region and provides a **text prompt** (e.g., "blue denim jacket").
4. System segments the selected region and **generates try-on output** using Segmind.

---

## ğŸŒ Frontend

The **frontend** for this project was built using [Lovable](https://lovable.dev) and connects directly with this backend API.
ğŸ”— [Frontend Repository](https://github.com/your-username/virtual-tryon-frontend) (replace with your actual repo link)

---

## ğŸ“œ License

MIT License Â© 2025 \[Your Name]

---

## ğŸ™Œ Acknowledgements

* [Roboflow](https://roboflow.com/) â€“ Clothing detection
* [Metaâ€™s SAM](https://segment-anything.com/) â€“ Image segmentation
* [Segmind](https://segmind.com/) â€“ Inpainting
* [FastAPI](https://fastapi.tiangolo.com/) â€“ API framework
